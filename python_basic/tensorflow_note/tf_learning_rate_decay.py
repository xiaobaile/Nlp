"""
æŒ‡æ•°è¡°å‡å­¦ä¹ ç‡ï¼š
    å­¦ä¹ ç‡éšç€è®­ç»ƒè½®æ•°å˜åŒ–è€ŒåŠ¨æ€æ›´æ–°ã€‚
    å­¦ä¹ ç‡è®¡ç®—å…¬å¼å¦‚ä¸‹:
        Learning_rate = LEARNING_RATE_BASE * LEARNING_RATE_DECAY *ï¼ˆğ’ˆğ’ğ’ğ’ƒğ’‚ğ’_ğ’”ğ’•ğ’†ğ’‘ /ğ‘³ğ‘¬ğ‘¨ğ‘¹ğ‘µğ‘°ğ‘µğ‘®_ğ‘¹ğ‘¨ğ‘»ğ‘¬_ğ‘©ğ‘¨ğ‘»ğ‘ªğ‘¯_ğ‘ºğ‘°ğ’ğ‘¬ï¼‰
    ç”¨ Tensorflow çš„å‡½æ•°è¡¨ç¤ºä¸º:
        global_step = tf.Variable(0, trainable=False)
        learning_rate = tf.train.exponential_decay(
                                                LEARNING_RATE_BASE,
                                                global_step,
                                                LEARNING_RATE_STEP, LEARNING_RATE_DECAY,
                                                staircase=True/False)
        å…¶ä¸­ï¼ŒLEARNING_RATE_BASE ä¸ºå­¦ä¹ ç‡åˆå§‹å€¼ï¼ŒLEARNING_RATE_DECAY ä¸ºå­¦ä¹ ç‡è¡°å‡ç‡,
        global_step è®°å½•äº†å½“å‰è®­ç»ƒè½®æ•°ï¼Œä¸ºä¸å¯è®­ç»ƒå‹å‚æ•°ã€‚
        å­¦ä¹ ç‡ learning_rate æ›´æ–°é¢‘ç‡ä¸ºè¾“å…¥æ•°æ®é›†æ€»æ ·æœ¬æ•°é™¤ä»¥æ¯æ¬¡å–‚å…¥æ ·æœ¬æ•°ã€‚
        è‹¥ staircase è®¾ç½®ä¸º True æ—¶ï¼Œè¡¨ç¤º global_step/learning rate step å–æ•´æ•°ï¼Œå­¦ä¹ ç‡é˜¶æ¢¯å‹è¡°å‡;
        è‹¥ staircase è®¾ç½®ä¸º false æ—¶ï¼Œå­¦ä¹ ç‡ä¼šæ˜¯ä¸€æ¡å¹³æ»‘ä¸‹é™çš„æ›²çº¿ã€‚
"""


import tensorflow as tf


""" æŸå¤±å‡½æ•°ï¼šloss = (w + 1)^2ï¼Œä»¤wåˆå€¼å€¼æ˜¯å¸¸æ•°10ã€‚åå‘ä¼ æ’­å°±æ˜¯æ±‚æœ€ä¼˜wï¼Œå³æ±‚æœ€å°losså¯¹åº”çš„wå€¼
ä½¿ç”¨æŒ‡æ•°è¡°å‡å­¦ä¹ ç‡ï¼Œåœ¨è¿­ä»£åˆæœŸå¾—åˆ°è¾ƒé«˜çš„ä¸‹é™é€Ÿåº¦ï¼Œå¯ä»¥åœ¨è¾ƒå°çš„è®­ç»ƒè½®æ•°ä¸‹å–å¾—æ›´æœ‰æ”¶æ•›æ€§ã€‚
"""
# åˆå§‹å­¦ä¹ ç‡
LEARNING_RATE_BASE = 1.0
# å­¦ä¹ ç‡è¡°å‡ç‡
LEARNING_RATE_DECAY = 0.99
# å–‚å…¥å¤šå°‘è½®BATCH_SIZEåï¼Œæ›´æ–°ä¸€æ¬¡å­¦ä¹ ç‡ï¼Œä¸€èˆ¬è®¾ä¸ºï¼šæ€»æ ·æœ¬æ•°/BATCH_SIZE
LEARNING_RATE_STEP = 1

# è¿è¡Œäº†å‡ è½®BATCH_SIZEçš„è®¡æ•°å™¨ï¼Œåˆå§‹å€¼ä¸º0ï¼Œ è®¾ç½®ä¸ºä¸è¢«è®­ç»ƒã€‚
global_step = tf.Variable(0, trainable=False)
# å®šä¹‰å­¦ä¹ ç‡ä¸ºæŒ‡æ•°è¡°å‡å­¦ä¹ ç‡
learning_rate = tf.train.exponential_decay(
    LEARNING_RATE_BASE,
    global_step,
    LEARNING_RATE_STEP,
    LEARNING_RATE_DECAY,
    staircase=True
)
# å®šä¹‰å¾…ä¼˜åŒ–å‚æ•°ï¼Œåˆå§‹å€¼ä¸º10
w = tf.Variable(tf.constant(5, dtype=tf.float32))
# å®šä¹‰æŸå¤±å‡½æ•°ã€‚
loss = tf.square(w+1)
# å®šä¹‰åå‘ä¼ æ’­æ–¹æ³•ã€‚
train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)
# ç”Ÿæˆä¼šè¯ï¼Œè®­ç»ƒ40è½®ã€‚
with tf.Session() as sess:
    init_op = tf.global_variables_initializer()
    sess.run(init_op)
    for i in range(40):
        sess.run(train_step)
        learning_rate_val = sess.run(learning_rate)
        global_step_val = sess.run(global_step)
        w_val = sess.run(w)
        loss_val = sess.run(loss)
        print("After %s steps: global_step is %f, w is %f, learning rate is %f, loss is %f..."
              % (i, global_step_val, w_val, learning_rate_val, loss_val))
